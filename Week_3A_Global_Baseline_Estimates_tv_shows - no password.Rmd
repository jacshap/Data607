---
title: "Week_3A_Survey_JRS"
author: "Jacob Shapiro"
date: "`r Sys.Date()`"
output: 
  html_document :
  df_print: paged
---
<style type="text/css">
.main-container {
  max-width: 100% !important;
  margin: auto;
}
options("width"=300)
</style>
<!-- Note need above for all columns to appear together -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
password <- ""
```

## Connecting to the PostgreSQL database and importing the table

Please note my friends don't watch a lot of movies that overlap so I decided to go with TV shows, and created some categories to get more data that could be explored later. 


```{r}
#utilizing IBM site here for connection https://dataplatform.cloud.ibm.com/exchange/public/entry/view/bf1d847b1638af654a0eb849842f85ee?context=cpdaas
#Note: had to install RTools
#install.packages("RPostgreSQL")
#install.packages("DBI")
library(DBI)
library(RPostgreSQL)
library(tidyverse)
library(dplyr)
library(tidyr)

#Enter the values for you database connection
dsn_database = "postgres"       # for example  "compose"
dsn_hostname = "localhost"     # for example  "aws-us-east-1-portal.4.dblayer.com"
dsn_port = "5432"                 # for example  11101 
dsn_uid = "postgres"        # for example  "admin"
dsn_pwd = password      # note: included in above chunk that is hidden in published version. Will delete as part of upload to github & this submission

tryCatch({
    drv <- dbDriver("PostgreSQL")
    print("Connecting to database")
    conn <- dbConnect(drv, 
                 dbname = dsn_database,
                 host = dsn_hostname, 
                 port = dsn_port,
                 user = dsn_uid, 
                 password = dsn_pwd)
    print("Connected!")
    },
    error=function(cond) {
            print("Unable to connect to database.")
    })

#Big Note: kept getting error that password was incorrect. Had to follow this video to fix (changed conf file and altered user in pgadmin) https://www.youtube.com/watch?v=CHYjDuaYA4M&ab_channel=DatabaseStar

#Tables that exist in the db
cursor <- dbGetQuery(conn, "SELECT datname from pg_database")
cursor$datname

df <- dbGetQuery(conn, "SELECT * FROM shows")

print(df)

```


## Interviewee averages

Going to just keep overall for purposes of this exercise

```{r}
df <- df %>% select(interviewees, tv_shows, overall)
```

Add averages per person and per movie

```{r}
df <- df %>% arrange(desc(interviewees))

df <- df %>% group_by(interviewees) %>% mutate(user_avg = mean(overall, na.rm = TRUE))

df <- df %>% group_by(tv_shows) %>% mutate(show_avg = mean(overall, na.rm = TRUE))
```

Average tv show rating

```{r}
avg_all_shows <- mean(df$show_avg)
```

User average rating - average for all shows

```{r}
df <- df %>% mutate(user_avg_minus_avg_show = user_avg - avg_all_shows)
```

show average - average for all shows

```{r}
df <- df %>% mutate(show_avg_minus_avg_show = show_avg - avg_all_shows)
```

Predict if someone will like something if not already filled in

```{r}
#rating_prediction <- df %>% mutate(overall_prediction = ifelse(overall != is.na(),
#                                  replace(avg_all_shows + show_avg_minus_avg_show + user_avg_minus_avg_show)
#                                   ))
#not working, can't figure out why

#df %>% replace_na(list(overall = (avg_all_shows + show_avg_minus_avg_show + user_avg_minus_avg_show)))

#rating_prediction <- df %>% mutate(overall = replace_na(overall, (avg_all_shows + show_avg_minus_avg_show + user_avg_minus_avg_show)))
#it's replacing everything, not sure how to just do ones that are NA
```

Ok, so another approach for this part was to make another dataframe of all empty fields to perform the calculation. I will try that approach and output that table, then do some examples.

First, calculate values:

```{r}
#table with empty "Overall" values
empty_table <- df %>% filter(is.na(overall))

#calculate values in overall field
empty_table <- empty_table %>% mutate(overall = avg_all_shows + show_avg_minus_avg_show + user_avg_minus_avg_show) #%>% select(interviewees, tv_shows, overall)
print(empty_table)
```

Stu hasn't seen several shows. Let's see which he should see next:

```{r}
Stus_show <- empty_table %>% filter(interviewees == "Stu") #%>% summarize(Stus_pick = max(overall))
print(Stus_show)
#Stus_show <- empty_table %>% group_by(overall, tv_shows) %>% filter(interviewees == "Stu") %>% slice(which.max(overall))
#empty_table %>% filter(interviewees == "Stu") %>% select(interviewees, tv_shows, overall) %>% top_n(n=1)
#It keeps grouping them and does one for each tv_shows. I just want one for Stu.

Stus_show %>% arrange(desc(overall)) %>% head(n=1) %>% select(tv_shows)

```

Looks like Stu should watch Peaky Blinders!

How about Valerie?

```{r}
Vals_show <- empty_table %>% filter(interviewees == "Stu") %>% arrange(desc(overall))
Vals_show %>% head(n=1) %>% select(tv_shows)
```

This is good to know as I've been trying to get her to watch Peaky Blinders!

# Done with assignment goals!

## Extra: Trying to replace NA values in overall column

I think we've hit the assignment core concept but for fun let's join the tables to get a filled out dataframe

```{r}
df$overall <-as.double(df$overall)
glimpse(df)
joined_empty <- left_join(df, empty_table, by = c("interviewees","tv_shows","user_avg","show_avg","user_avg_minus_avg_show","show_avg_minus_avg_show"))
knitr::kable(joined_empty)
```

I really don't understand why there is overall.x and overall.y but if I include "overall" in the "by =" argument then the values from empty_table disappear. I made sure both are the same type, not sure why it's not combining into one column.

Try a full join?

```{r}
joined_empty <- full_join(df, empty_table) %>% group_by(interviewees,tv_shows)
knitr::kable(joined_empty)

#maybe rbind?
joined_empty <- rbind(df,empty_table)
knitr::kable(joined_empty)
```

Neither work, they just put the empty_table values at the bottom. Kinda lost on this aspect.